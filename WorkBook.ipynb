{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string, re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('news.json',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>Melissa Jeltsen</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                           headline  \\\n",
       "0    CRIME  There Were 2 Mass Shootings In Texas Last Week...   \n",
       "\n",
       "           authors                                               link  \\\n",
       "0  Melissa Jeltsen  https://www.huffingtonpost.com/entry/texas-ama...   \n",
       "\n",
       "                                   short_description       date  \n",
       "0  She left her husband. He killed their children... 2018-05-26  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all categories that the articles are categorized by\n",
    "categories = list(df.category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CRIME',\n",
       " 'ENTERTAINMENT',\n",
       " 'WORLD NEWS',\n",
       " 'IMPACT',\n",
       " 'POLITICS',\n",
       " 'WEIRD NEWS',\n",
       " 'BLACK VOICES',\n",
       " 'WOMEN',\n",
       " 'COMEDY',\n",
       " 'QUEER VOICES',\n",
       " 'SPORTS',\n",
       " 'BUSINESS',\n",
       " 'TRAVEL',\n",
       " 'MEDIA',\n",
       " 'TECH',\n",
       " 'RELIGION',\n",
       " 'SCIENCE',\n",
       " 'LATINO VOICES',\n",
       " 'EDUCATION',\n",
       " 'COLLEGE',\n",
       " 'PARENTS',\n",
       " 'ARTS & CULTURE',\n",
       " 'STYLE',\n",
       " 'GREEN',\n",
       " 'TASTE',\n",
       " 'HEALTHY LIVING',\n",
       " 'THE WORLDPOST',\n",
       " 'GOOD NEWS',\n",
       " 'WORLDPOST',\n",
       " 'FIFTY',\n",
       " 'ARTS',\n",
       " 'WELLNESS',\n",
       " 'PARENTING',\n",
       " 'HOME & LIVING',\n",
       " 'STYLE & BEAUTY',\n",
       " 'DIVORCE',\n",
       " 'WEDDINGS',\n",
       " 'FOOD & DRINK',\n",
       " 'MONEY',\n",
       " 'ENVIRONMENT',\n",
       " 'CULTURE & ARTS']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classfication\n",
    "Going to use the headline and the short description to try and predict the category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There Were 2 Mass Shootings In Texas Last Week, But Only 1 On TV'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.headline[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'She left her husband. He killed their children. Just another day in America.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.short_description[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to use the headline and the short description as the same importance. Combining the two will then be used to try and predict the category that it belongs to based on the words used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a period at the end of the headline to be combined\n",
    "#   with the short description\n",
    "df.headline = df.headline+'. '\n",
    "# combining the two together\n",
    "df['text'] = df.headline + df.short_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There Were 2 Mass Shootings In Texas Last Week, But Only 1 On TV. She left her husband. He killed their children. Just another day in America.\n"
     ]
    }
   ],
   "source": [
    "print(df.text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.text\n",
    "target = df.category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to get the more important words in the descriptions I am going to remove the stop words. Stop words are words like and, or, the, and many more that do not give any 'information' on what that article title/short description is describing.\n",
    "\n",
    "If the word 'gun' appears in an article title then the article is most likely about crime and not entertainment. If the word 'baseball' appears in an article then it is most likely about sports. There are interesting words like 'court' where it could be referring to a basketball court or a court where trails in criminal and civil cases are conducted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to filter out stopwords and punctions to get root words\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words += list(string.punctuation)\n",
    "stop_words = set(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to remove the stopwords from the data\n",
    "# splitting data into tokens meaning a list of individual words\n",
    "def remove_stopwords(article_text):\n",
    "    '''\n",
    "    INPUT: Text of any kind\n",
    "    OUTPUT: Text with all stop words removed\n",
    "    '''\n",
    "    tokens = nltk.word_tokenize(article_text)\n",
    "    article_without_stopwords = [token.lower() for token in tokens if token.lower() not in stop_words]\n",
    "    return article_without_stopwords\n",
    "    \n",
    "data_wo_stopwords = list(map(remove_stopwords,data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:\n",
      "There Were 2 Mass Shootings In Texas Last Week, But Only 1 On TV. She left her husband. He killed their children. Just another day in America.\n",
      "\n",
      "Tokenized + Removed Stop Words:\n",
      "['2', 'mass', 'shootings', 'texas', 'last', 'week', '1', 'tv', 'left', 'husband', 'killed', 'children', 'another', 'day', 'america']\n"
     ]
    }
   ],
   "source": [
    "print('Normal:')\n",
    "print(data[0]+'\\n')\n",
    "print('Tokenized + Removed Stop Words:')\n",
    "print(data_wo_stopwords[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118709"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the total vocab is a list of all words used in every article\n",
    "total_vocab = set()\n",
    "for word in data_wo_stopwords:\n",
    "    total_vocab.update(word)\n",
    "len(total_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to lemmatize the text data in order to reduce the total vocab. Lemmatization is the process of removing different conguations of the same word. Organize, organizes, and organizing are all the same word but with different endings to describe if it is happening and when it is happening. The process of lemmatization will remove these so that all 3 words will transform just into organize and will be treated the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_data = []\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for article in data_wo_stopwords:\n",
    "    lemmatized_article = ' '.join([lemmatizer.lemmatize(word) for word in article])\n",
    "    lemmatized_data.append(lemmatized_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:\n",
      "There Were 2 Mass Shootings In Texas Last Week, But Only 1 On TV. She left her husband. He killed their children. Just another day in America. \n",
      "\n",
      "Tokenized + Removed Stop Words:\n",
      "['2', 'mass', 'shootings', 'texas', 'last', 'week', '1', 'tv', 'left', 'husband', 'killed', 'children', 'another', 'day', 'america'] \n",
      "\n",
      "Lemmatized:\n",
      "2 mass shooting texas last week 1 tv left husband killed child another day america\n"
     ]
    }
   ],
   "source": [
    "print('Normal:')\n",
    "print(data[0],'\\n')\n",
    "print('Tokenized + Removed Stop Words:')\n",
    "print(data_wo_stopwords[0],'\\n')\n",
    "print('Lemmatized:')\n",
    "print(lemmatized_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = lemmatized_data\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
